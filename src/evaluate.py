
from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score
import numpy as np
def evaluate_model(pipeline, X_test, y_test):
    print("\nðŸ”® Making predictions...")
    y_pred = pipeline.predict(X_test)
    print(f"âœ… Predicted {len(y_pred)} samples")
    
    # Calculate metrics
    print("\nðŸ“ˆ Calculating metrics...")
    
    rmse = np.sqrt(mean_squared_error(y_test, y_pred))
    mae = mean_absolute_error(y_test, y_pred)
    r2 = r2_score(y_test, y_pred)
    
    metrics = {
        'rmse': rmse,
        'mae': mae,
        'r2': r2
    }
    print("EVALUATION RESULTS:")
    print("â”€" * 60)
    print(f"  ðŸ“‰ RMSE (Root Mean Squared Error): {rmse:.4f}")
    print(f"  ðŸ“‰ MAE  (Mean Absolute Error):     {mae:.4f}")
    print(f"  ðŸ“ˆ RÂ²   (R-Squared Score):         {r2:.4f}")
    print("â”€" * 60)
    
    print("\nðŸ’¡ What these metrics mean:")
    print(f"  â€¢ RMSE: Average prediction error is ${rmse:.2f} (in $100,000s)")
    print(f"  â€¢ MAE:  Typical error is ${mae:.2f}")
    print(f"  â€¢ RÂ²:   Model explains {r2*100:.1f}% of variance")
    
    print("\n" + "=" * 60)
    print("âœ… EVALUATION COMPLETE!")
    print("=" * 60)
    
    return metrics


if __name__ == "__main__":
    from data import load_dataset, split_data
    from train import train_model
    
    print("\nðŸ§ª TESTING EVALUATION MODULE\n")
    print("--- Step 1: Training a model ---")
    pipeline = train_model(
        model_name='random_forest',
        use_pca=False,
        use_poly=False,
        tune_hyperparams=False
    )
    
    # Load test data
    print("\n--- Step 2: Loading test data ---")
    X, y, features = load_dataset()
    X_train, X_test, y_train, y_test = split_data(X, y)
    
    # Evaluate
    print("\n--- Step 3: Evaluating model ---")
    metrics = evaluate_model(pipeline, X_test, y_test)
    print("\nâœ… Evaluation test completed!")
    print(f"\nðŸ“Š Final Metrics: {metrics}")
    